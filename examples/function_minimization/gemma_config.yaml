# Configuration for function minimization example with local Gemma
max_iterations: 10
checkpoint_interval: 5
log_level: "DEBUG"  # Enable detailed debug logging to track all operations

# LLM configuration
llm:
  models:
    - name: "gemma-local"
      model_path: "e:\\Project\\AI\\GemmaEvolve\\gemma-3-4b-it-UD-Q4_K_XL.gguf"
      n_ctx: 32768  # Increased from 4096 to better utilize model capacity (trained with 131k)
      n_gpu_layers: 0
      temperature: 0.7
      top_p: 0.95
      max_tokens: 4096  # Increased from 2048 to match larger context
      
  evaluator_models:
    - name: "gemma-local" 
      model_path: "e:\\Project\\AI\\GemmaEvolve\\gemma-3-4b-it-UD-Q4_K_XL.gguf"
      n_ctx: 32768  # Increased from 4096 to better utilize model capacity
      n_gpu_layers: 0

# Prompt configuration
prompt:
  system_message: "You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms."

# Database configuration
database:
  population_size: 10 
  archive_size: 5
  num_islands: 1 
  elite_selection_ratio: 0.2
  exploitation_ratio: 0.7
  # embedding_model disabled for local run

# Evaluator configuration
evaluator:
  timeout: 60
  cascade_thresholds: [1.3]
  parallel_evaluations: 1

# Evolution settings
diff_based_evolution: true
max_code_length: 20000
