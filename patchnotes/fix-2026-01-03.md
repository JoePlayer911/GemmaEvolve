# Fix 2026-01-03

## VRAM Optimization
We solved a persistent "Out of Memory" issue where the Main Process (Controller) was silently hoarding VRAM. Even though the Controller doesn't run the heavy evolution evaluations, it was loading a copy of the model at startup "just in case."

This meant that on a 4-GPU system, GPU 0 was already losing 7GB to the idle Controller before the actual Worker process even tried to start.

## Zero-VRAM Controller
We refactored the loading logic to be "Lazy." The Controller now initializes strictly on the CPU and refuses to touch the GPU unless absolutely necessary. If it needs to check a model, it loads it, does the check, and immediately destroys it.

This ensures that when the heavy-lifting Worker processes start, they have 100% of the VRAM available to them.

## Quantization Strategy
We also made a strategic switch from **Q8** (12.5GB) to **Q4** (7.3GB) for heavily parallel runs. While Q8 is smarter, Q4 fits comfortably entirely within a single 1080 Ti's memory, allowing us to run 4 concurrent evaluations (one per card) instead of just 2. For evolutionary algorithms, 4x speed often beats 1.5x smarts.

```yaml
# gemma_config.yaml
parallel_evaluations: 2 # Can now go up to 4 safely with Q4
```
