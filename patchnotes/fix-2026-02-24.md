# Patch Notes: 2026-02-24 - Llama-cpp Fixes & Benchmark Jump-Start

## Fixes

*   **Fixed `llama_cpp` Library Loading Error**: Resolved the `OSError: libcudart.so.12: cannot open shared object file: No such file or directory` error that occurred when importing `llama_cpp`. This was fixed by installing the necessary CUDA runtime and mathematical libraries (`nvidia-cuda-runtime-cu12`, `nvidia-cublas-cu12`, `nvidia-cusparse-cu12`, etc.) directly into the virtual environment.
*   **Persistent CUDA Library Path**: Modified the `venv/bin/activate` script to automatically inject and export the correct `LD_LIBRARY_PATH` pointing to the internal NVIDIA package directories whenever the virtual environment is activated.

## New Features

*   **OpenEvolve Jump-Start**: Implemented a core improvement in `benchmark_verilog.py`. The script now captures the natively generated code from the Pure Gemma Baseline and passes it as the `initial_program` for the OpenEvolve optimization process. This allows OpenEvolve to start from a functional model generation instead of an empty or template file, significantly increasing evolution success rates.
*   **One-Click Benchmark Script**: Created `run_benchmark.sh` to simplify running the Verilog benchmarks. This script automatically activates the virtual environment (ensuring all environment variables are set) and passes any command-line arguments to the underlying Python script.

## Technical Details

*   **Added Dependencies**:
    *   `nvidia-cuda-runtime-cu12`
    *   `nvidia-cublas-cu12`
    *   `nvidia-cusolver-cu12`
    *   `nvidia-cusparse-cu12`
    *   `nvidia-curand-cu12`
    *   `nvidia-cufft-cu12`
    *   `nvidia-nvjitlink-cu12`
*   **Modified Files**:
    *   `venv/bin/activate`: Added `LD_LIBRARY_PATH` logic.
    *   `benchmark_verilog.py`: Updated logic to save/load `baseline_generated.v`.
    *   `run_benchmark.sh`: New execution shell script.
